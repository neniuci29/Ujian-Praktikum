{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPx+HgkeYcWuGcRo4wKsiyG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neniuci29/Ujian-Praktikum/blob/main/2302050119_Neni_uci_naibaho_UjianAkhir_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wCZ1DnV_7iE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "=================================================\n",
        "UJIAN AKHIR PRAKTIKUM KECERDASAN BUATAN\n",
        "Klasifikasi Gambar - Deteksi Pneumonia\n",
        "=================================================\n",
        "Nama Lengkap : [Neni Uci Naibaho]\n",
        "NPM          : [2302050119]\n",
        "Kelas        : [IK4]\n",
        "Tanggal Ujian: [12 JAN 2026]\n",
        "=================================================\n",
        "\"\"\"\n",
        "print(\"Identitas berhasil dimuat!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 1: IMPORT LIBRARY\n",
        "# ==========================================\n",
        "\n",
        "# Library dasar\n",
        "import os, shutil\n",
        "import zipfile\n",
        "import random\n",
        "from random import sample\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm as tq\n",
        "\n",
        "# Library untuk visualisasi\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"âœ“ Library dasar berhasil diimport!\")\n"
      ],
      "metadata": {
        "id": "E9ywaxhoAew7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Library untuk pemrosesan gambar\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import skimage\n",
        "from skimage import io\n",
        "from skimage.transform import resize, rotate, AffineTransform, warp\n",
        "from skimage import img_as_ubyte\n",
        "from skimage.exposure import adjust_gamma\n",
        "from skimage.util import random_noise\n",
        "\n",
        "print(\"âœ“ Library image processing berhasil diimport!\")\n"
      ],
      "metadata": {
        "id": "W8NSR6yNAjN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Library untuk machine learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from tensorflow.keras import Model, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.layers import (InputLayer, Conv2D, MaxPooling2D, MaxPool2D,\n",
        "                                     Dense, Flatten, Dropout, BatchNormalization)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Nonaktifkan warning\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Cek versi TensorFlow\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(\"âœ“ Library ML berhasil diimport!\")\n"
      ],
      "metadata": {
        "id": "cAOltvmqAnzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 2: DOWNLOAD DATASET DARI KAGGLE\n",
        "# ==========================================\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"UPLOAD FILE KAGGLE.JSON\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\nLangkah:\")\n",
        "print(\"1. Klik 'Choose Files' yang akan muncul di bawah\")\n",
        "print(\"2. Pilih file 'kaggle.json' dari komputer Anda\")\n",
        "print(\"3. Tunggu hingga upload selesai (ada centang hijau)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "print(\"\\nâœ“ Kaggle token berhasil diupload!\")\n"
      ],
      "metadata": {
        "id": "zIxSl2xbAsQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Kaggle credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"âœ“ Kaggle API berhasil dikonfigurasi!\")\n"
      ],
      "metadata": {
        "id": "Bu51QKukAz1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset pneumonia dari Kaggle\n",
        "print(\"Downloading dataset... (ini akan memakan waktu 2-5 menit)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "!kaggle datasets download -d tolgadincer/labeled-chest-xray-images\n",
        "\n",
        "print(\"\\nâœ“ Dataset berhasil didownload!\")\n",
        "print(\"\\nExtracting dataset...\")\n",
        "\n",
        "!unzip -q labeled-chest-xray-images.zip\n",
        "\n",
        "print(\"âœ“ Dataset berhasil diekstrak!\")\n",
        "print(\"\\nStruktur folder:\")\n",
        "!ls -la chest_xray/\n"
      ],
      "metadata": {
        "id": "C9WN-jHaA3lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 3: DATA PREPARATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"Menggabungkan dataset train dan test...\")\n",
        "\n",
        "# Direktori sumber\n",
        "train_dir = \"chest_xray/train\"\n",
        "test_dir = \"chest_xray/test\"\n",
        "\n",
        "# Direktori tujuan (gabungan)\n",
        "combined_dir = \"chest_xray/dataset\"\n",
        "\n",
        "# Buat folder dataset\n",
        "os.makedirs(combined_dir, exist_ok=True)\n",
        "\n",
        "# Salin dari train\n",
        "for category in os.listdir(train_dir):\n",
        "    category_dir = os.path.join(train_dir, category)\n",
        "    if os.path.isdir(category_dir):\n",
        "        shutil.copytree(category_dir, os.path.join(combined_dir, category),\n",
        "                       dirs_exist_ok=True)\n",
        "        print(f\"âœ“ Copied {category} from train\")\n",
        "\n",
        "# Salin dari test\n",
        "for category in os.listdir(test_dir):\n",
        "    category_dir = os.path.join(test_dir, category)\n",
        "    if os.path.isdir(category_dir):\n",
        "        shutil.copytree(category_dir, os.path.join(combined_dir, category),\n",
        "                       dirs_exist_ok=True)\n",
        "        print(f\"âœ“ Copied {category} from test\")\n",
        "\n",
        "print(\"\\nâœ“ Dataset berhasil digabungkan!\")\n"
      ],
      "metadata": {
        "id": "NoUv5Dz6BFVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat dictionary untuk menyimpan daftar gambar\n",
        "lung_image = {}\n",
        "\n",
        "path = \"chest_xray/\"\n",
        "path_sub = os.path.join(path, \"dataset\")\n",
        "\n",
        "for category in os.listdir(path_sub):\n",
        "    lung_image[category] = os.listdir(os.path.join(path_sub, category))\n",
        "    print(f\"{category}: {len(lung_image[category])} gambar\")\n",
        "\n",
        "print(\"\\nâœ“ Dataset exploration selesai!\")\n"
      ],
      "metadata": {
        "id": "-TsIikMYBMXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan 5 gambar random dari setiap kelas\n",
        "path_sub = \"chest_xray/dataset/\"\n",
        "\n",
        "fig, axs = plt.subplots(len(lung_image.keys()), 5, figsize=(15, 10))\n",
        "\n",
        "for i, class_name in enumerate(os.listdir(path_sub)):\n",
        "    images = np.random.choice(lung_image[class_name], 5, replace=False)\n",
        "\n",
        "    for j, image_name in enumerate(images):\n",
        "        img_path = os.path.join(path_sub, class_name, image_name)\n",
        "        img = Image.open(img_path).convert(\"L\")  # Grayscale\n",
        "        axs[i, j].imshow(img, cmap='gray')\n",
        "        axs[i, j].set(xlabel=class_name, xticks=[], yticks=[])\n",
        "\n",
        "fig.suptitle('Sample Images from Each Class', fontsize=16, y=1.02)\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ“ Visualisasi selesai!\")\n"
      ],
      "metadata": {
        "id": "FxhW9qu_BT7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung distribusi data\n",
        "lung_path = \"chest_xray/dataset/\"\n",
        "\n",
        "file_name = []\n",
        "labels = []\n",
        "full_path = []\n",
        "\n",
        "for path, subdirs, files in os.walk(lung_path):\n",
        "    for name in files:\n",
        "        full_path.append(os.path.join(path, name))\n",
        "        labels.append(path.split('/')[-1])\n",
        "        file_name.append(name)\n",
        "\n",
        "distribution_df = pd.DataFrame({\n",
        "    \"path\": full_path,\n",
        "    'file_name': file_name,\n",
        "    \"labels\": labels\n",
        "})\n",
        "\n",
        "# Plot distribusi\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.countplot(x=distribution_df['labels'], palette='Set2')\n",
        "plt.title('Distribusi Data Sebelum Augmentasi', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Kelas')\n",
        "plt.ylabel('Jumlah Gambar')\n",
        "\n",
        "# Tambahkan angka di atas bar\n",
        "for p in plt.gca().patches:\n",
        "    plt.gca().text(p.get_x() + p.get_width()/2., p.get_height(),\n",
        "                   f'{int(p.get_height())}',\n",
        "                   ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Print statistik\n",
        "print(\"\\nDistribusi Data:\")\n",
        "print(distribution_df['labels'].value_counts())\n",
        "print(f\"\\nTotal gambar: {len(distribution_df)}\")\n"
      ],
      "metadata": {
        "id": "usLm8WGLBbmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 4: DATA AUGMENTATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"Membuat fungsi augmentasi...\")\n",
        "\n",
        "# Rotasi berlawanan arah jarum jam\n",
        "def anticlockwise_rotation(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    angle = random.randint(0, 180)\n",
        "    return rotate(img, angle)\n",
        "\n",
        "# Rotasi searah jarum jam\n",
        "def clockwise_rotation(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    angle = random.randint(0, 180)\n",
        "    return rotate(img, -angle)\n",
        "\n",
        "# Flip vertikal\n",
        "def flip_up_down(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return np.flipud(img)\n",
        "\n",
        "# Brightness adjustment\n",
        "def add_brightness(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return adjust_gamma(img, gamma=0.5, gain=1)\n",
        "\n",
        "# Blur\n",
        "def blur_image(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    return cv2.GaussianBlur(img, (9, 9), 0)\n",
        "\n",
        "# Shear\n",
        "def sheared(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    transform = AffineTransform(shear=0.2)\n",
        "    return warp(img, transform, mode=\"wrap\")\n",
        "\n",
        "# Warp shift\n",
        "def warp_shift(img):\n",
        "    img = cv2.cvtColor(img, 0)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    transform = AffineTransform(translation=(0, 40))\n",
        "    return warp(img, transform, mode=\"wrap\")\n",
        "\n",
        "print(\"âœ“ Fungsi augmentasi berhasil dibuat!\")\n",
        "print(\"\\nFungsi yang tersedia:\")\n",
        "print(\"1. Rotation (clockwise & anticlockwise)\")\n",
        "print(\"2. Flip (up-down)\")\n",
        "print(\"3. Brightness adjustment\")\n",
        "print(\"4. Blur\")\n",
        "print(\"5. Shear\")\n",
        "print(\"6. Warp shift\")\n"
      ],
      "metadata": {
        "id": "7DDVtknzBiDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary transformasi\n",
        "transformations = {\n",
        "    'rotate anticlockwise': anticlockwise_rotation,\n",
        "    'rotate clockwise': clockwise_rotation,\n",
        "    'warp shift': warp_shift,\n",
        "    'blurring image': blur_image,\n",
        "    'add brightness': add_brightness,\n",
        "    'flip up down': flip_up_down,\n",
        "    'shear image': sheared\n",
        "}\n",
        "\n",
        "# Path gambar\n",
        "images_path = \"chest_xray/dataset/NORMAL\"\n",
        "augmented_path = \"chest_xray/dataset/NORMAL\"\n",
        "images = []\n",
        "\n",
        "# Baca semua gambar NORMAL\n",
        "for im in os.listdir(images_path):\n",
        "    images.append(os.path.join(images_path, im))\n",
        "\n",
        "print(f\"Total gambar NORMAL saat ini: {len(images)}\")\n",
        "\n",
        "# Target augmentasi: tambah 2000 gambar\n",
        "images_to_generate = 2000\n",
        "\n",
        "print(f\"\\nMemulai augmentasi untuk menambah {images_to_generate} gambar...\")\n",
        "print(\"Ini akan memakan waktu 3-5 menit. Mohon tunggu...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "i = 1\n",
        "success_count = 0\n",
        "error_count = 0\n",
        "\n",
        "while i <= images_to_generate:\n",
        "    image = random.choice(images)\n",
        "    try:\n",
        "        original_image = io.imread(image)\n",
        "        transformed_image = None\n",
        "        n = 0\n",
        "        transformation_count = random.randint(1, len(transformations))\n",
        "\n",
        "        while n <= transformation_count:\n",
        "            key = random.choice(list(transformations))\n",
        "            transformed_image = transformations[key](original_image)\n",
        "            n += 1\n",
        "\n",
        "        new_image_path = f\"{augmented_path}/augmented_image_{i}.jpg\"\n",
        "        transformed_image = img_as_ubyte(transformed_image)\n",
        "        cv2.imwrite(new_image_path, transformed_image)\n",
        "\n",
        "        success_count += 1\n",
        "\n",
        "        # Progress indicator setiap 100 gambar\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Progress: {i}/{images_to_generate} gambar ({(i/images_to_generate)*100:.1f}%)\")\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        error_count += 1\n",
        "        if error_count < 10:  # Only print first 10 errors\n",
        "            print(f\"Error pada gambar {image}: {str(e)[:50]}...\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nâœ“ Augmentasi selesai!\")\n",
        "print(f\"Berhasil: {success_count} gambar\")\n",
        "print(f\"Error: {error_count} gambar\")\n"
      ],
      "metadata": {
        "id": "nL7-rcIIBkxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung ulang distribusi\n",
        "lung_path = \"chest_xray/dataset/\"\n",
        "\n",
        "file_name = []\n",
        "labels = []\n",
        "full_path = []\n",
        "\n",
        "for path, subdirs, files in os.walk(lung_path):\n",
        "    for name in files:\n",
        "        full_path.append(os.path.join(path, name))\n",
        "        labels.append(path.split('/')[-1])\n",
        "        file_name.append(name)\n",
        "\n",
        "distribution_after = pd.DataFrame({\n",
        "    \"path\": full_path,\n",
        "    'file_name': file_name,\n",
        "    \"labels\": labels\n",
        "})\n",
        "\n",
        "# Plot perbandingan\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Before augmentation\n",
        "sns.countplot(x=distribution_df['labels'], palette='Set1', ax=ax1)\n",
        "ax1.set_title('Sebelum Augmentasi', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Kelas')\n",
        "ax1.set_ylabel('Jumlah Gambar')\n",
        "\n",
        "for p in ax1.patches:\n",
        "    ax1.text(p.get_x() + p.get_width()/2., p.get_height(),\n",
        "             f'{int(p.get_height())}',\n",
        "             ha='center', va='bottom')\n",
        "\n",
        "# After augmentation\n",
        "sns.countplot(x=distribution_after['labels'], palette='Set2', ax=ax2)\n",
        "ax2.set_title('Setelah Augmentasi', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Kelas')\n",
        "ax2.set_ylabel('Jumlah Gambar')\n",
        "\n",
        "for p in ax2.patches:\n",
        "    ax2.text(p.get_x() + p.get_width()/2., p.get_height(),\n",
        "             f'{int(p.get_height())}',\n",
        "             ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistik\n",
        "print(\"\\nDistribusi Setelah Augmentasi:\")\n",
        "print(distribution_after['labels'].value_counts())\n",
        "print(f\"\\nTotal gambar: {len(distribution_after)}\")\n",
        "print(\"\\nâœ“ Data sudah lebih seimbang!\")\n"
      ],
      "metadata": {
        "id": "P_V6k5QBB9Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 5: DATA SPLITTING\n",
        "# ==========================================\n",
        "\n",
        "mypath = 'chest_xray/dataset/'\n",
        "\n",
        "file_name = []\n",
        "labels = []\n",
        "full_path = []\n",
        "\n",
        "for path, subdirs, files in os.walk(mypath):\n",
        "    for name in files:\n",
        "        full_path.append(os.path.join(path, name))\n",
        "        labels.append(path.split('/')[-1])\n",
        "        file_name.append(name)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"path\": full_path,\n",
        "    'file_name': file_name,\n",
        "    \"labels\": labels\n",
        "})\n",
        "\n",
        "print(\"DataFrame berhasil dibuat!\")\n",
        "print(f\"Total data: {len(df)}\")\n",
        "print(\"\\nDistribusi per kelas:\")\n",
        "print(df.groupby(['labels']).size())\n"
      ],
      "metadata": {
        "id": "qQ6S6VV7CIQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pisahkan features dan labels\n",
        "X = df['path']\n",
        "y = df['labels']\n",
        "\n",
        "# Split 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=300,\n",
        "    stratify=y  # Pastikan distribusi seimbang\n",
        ")\n",
        "\n",
        "print(\"Split berhasil!\")\n",
        "print(f\"Train: {len(X_train)} gambar ({(len(X_train)/len(df))*100:.1f}%)\")\n",
        "print(f\"Test:  {len(X_test)} gambar ({(len(X_test)/len(df))*100:.1f}%)\")\n",
        "\n",
        "# Buat DataFrame terpisah\n",
        "df_train = pd.DataFrame({'path': X_train, 'labels': y_train, 'set': 'train'})\n",
        "df_test = pd.DataFrame({'path': X_test, 'labels': y_test, 'set': 'test'})\n",
        "\n",
        "# Gabungkan\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "\n",
        "print(\"\\nDistribusi per set dan label:\")\n",
        "print(df_all.groupby(['set', 'labels']).size())\n"
      ],
      "metadata": {
        "id": "oNkfmE4ECNdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path dataset final\n",
        "datasource_path = \"chest_xray/dataset/\"\n",
        "dataset_path = \"Dataset-Final/\"\n",
        "\n",
        "print(\"Membuat struktur folder dan menyalin file...\")\n",
        "print(\"Ini akan memakan waktu 2-3 menit...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "copied_count = 0\n",
        "total_files = len(df_all)\n",
        "\n",
        "for index, row in tq(df_all.iterrows(), total=total_files):\n",
        "    # Get file path\n",
        "    file_path = row['path']\n",
        "\n",
        "    # Buat folder tujuan jika belum ada\n",
        "    dest_dir = os.path.join(dataset_path, row['set'], row['labels'])\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "    # Tentukan file tujuan\n",
        "    destination_file_name = file_path.split('/')[-1]\n",
        "    file_dest = os.path.join(dest_dir, destination_file_name)\n",
        "\n",
        "    # Copy file\n",
        "    if not os.path.exists(file_dest):\n",
        "        shutil.copy2(file_path, file_dest)\n",
        "        copied_count += 1\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nâœ“ Selesai! {copied_count} file berhasil disalin\")\n",
        "\n",
        "# Verifikasi struktur\n",
        "print(\"\\nStruktur folder:\")\n",
        "print(f\"Dataset-Final/\")\n",
        "print(f\"â”œâ”€â”€ train/\")\n",
        "print(f\"â”‚   â”œâ”€â”€ NORMAL/ ({len(os.listdir('Dataset-Final/train/NORMAL'))} files)\")\n",
        "print(f\"â”‚   â””â”€â”€ PNEUMONIA/ ({len(os.listdir('Dataset-Final/train/PNEUMONIA'))} files)\")\n",
        "print(f\"â””â”€â”€ test/\")\n",
        "print(f\"    â”œâ”€â”€ NORMAL/ ({len(os.listdir('Dataset-Final/test/NORMAL'))} files)\")\n",
        "print(f\"    â””â”€â”€ PNEUMONIA/ ({len(os.listdir('Dataset-Final/test/PNEUMONIA'))} files)\")\n"
      ],
      "metadata": {
        "id": "zX2LWb_fCSfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 6: IMAGE DATA GENERATOR\n",
        "# ==========================================\n",
        "\n",
        "# Definisikan direktori\n",
        "TRAIN_DIR = \"Dataset-Final/train/\"\n",
        "TEST_DIR = \"Dataset-Final/test/\"\n",
        "\n",
        "train_normal = os.path.join(TRAIN_DIR, 'NORMAL')\n",
        "train_pneumonia = os.path.join(TRAIN_DIR, 'PNEUMONIA')\n",
        "test_normal = os.path.join(TEST_DIR, 'NORMAL')\n",
        "test_pneumonia = os.path.join(TEST_DIR, 'PNEUMONIA')\n",
        "\n",
        "# Hitung jumlah gambar\n",
        "print(\"Distribusi Data:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Training Set:\")\n",
        "print(f\"  - NORMAL: {len(os.listdir(train_normal))} gambar\")\n",
        "print(f\"  - PNEUMONIA: {len(os.listdir(train_pneumonia))} gambar\")\n",
        "print(f\"  - Total: {len(os.listdir(train_normal)) + len(os.listdir(train_pneumonia))} gambar\")\n",
        "print(f\"\\nTest Set:\")\n",
        "print(f\"  - NORMAL: {len(os.listdir(test_normal))} gambar\")\n",
        "print(f\"  - PNEUMONIA: {len(os.listdir(test_pneumonia))} gambar\")\n",
        "print(f\"  - Total: {len(os.listdir(test_normal)) + len(os.listdir(test_pneumonia))} gambar\")\n",
        "print(\"=\" * 50)\n"
      ],
      "metadata": {
        "id": "qmlMOVLxCX6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat ImageDataGenerator dengan normalisasi\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255.,  # Normalisasi [0, 1]\n",
        "    validation_split=0.2  # 20% untuk validasi\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "# Train generator\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Test generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=1,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"\\nâœ“ Data generators berhasil dibuat!\")\n",
        "print(\"\\nClass indices:\")\n",
        "print(train_generator.class_indices)\n"
      ],
      "metadata": {
        "id": "gDpQuL7LCcg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 7: MODEL BUILDING\n",
        "# ==========================================\n",
        "\n",
        "# Clear session (jika ada model sebelumnya)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Inisialisasi model\n",
        "model = Sequential(name='Pneumonia_CNN')\n",
        "\n",
        "# BLOCK 1: Conv2D + BatchNorm + MaxPooling\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu',\n",
        "                 input_shape=(150, 150, 1), name='conv1'))\n",
        "model.add(BatchNormalization(name='bn1'))\n",
        "model.add(MaxPool2D((2, 2), name='pool1'))\n",
        "\n",
        "# BLOCK 2: Conv2D + BatchNorm + MaxPooling\n",
        "model.add(Conv2D(32, (4, 4), padding='same', activation='relu', name='conv2'))\n",
        "model.add(BatchNormalization(name='bn2'))\n",
        "model.add(MaxPool2D((2, 2), name='pool2'))\n",
        "\n",
        "# BLOCK 3: Conv2D + BatchNorm + MaxPooling\n",
        "model.add(Conv2D(32, (7, 7), padding='same', activation='relu', name='conv3'))\n",
        "model.add(BatchNormalization(name='bn3'))\n",
        "model.add(MaxPool2D((2, 2), name='pool3'))\n",
        "\n",
        "# FLATTEN\n",
        "model.add(Flatten(name='flatten'))\n",
        "\n",
        "# DENSE LAYERS\n",
        "model.add(Dense(128, activation='relu', name='dense1'))\n",
        "model.add(Dropout(0.5, name='dropout1'))\n",
        "\n",
        "model.add(Dense(64, activation='relu', name='dense2'))\n",
        "model.add(Dropout(0.3, name='dropout2'))\n",
        "\n",
        "# OUTPUT LAYER\n",
        "model.add(Dense(1, activation='sigmoid', name='output'))\n",
        "\n",
        "print(\"âœ“ Model berhasil dibuat!\")\n"
      ],
      "metadata": {
        "id": "ye1pfVweCgku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=RMSprop(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Tampilkan summary\n",
        "print(model.summary())\n",
        "\n",
        "# Hitung total parameters\n",
        "total_params = model.count_params()\n",
        "print(f\"\\nTotal Parameters: {total_params:,}\")\n"
      ],
      "metadata": {
        "id": "ot2VT5YCClmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 8: TRAINING MODEL\n",
        "# ==========================================\n",
        "\n",
        "# Hitung class weights untuk handle imbalance\n",
        "count_normal = len(os.listdir(train_normal))\n",
        "count_pneumonia = len(os.listdir(train_pneumonia))\n",
        "\n",
        "total = count_normal + count_pneumonia\n",
        "weight_0 = (1 / count_normal) * (total / 2.0)\n",
        "weight_1 = (1 / count_pneumonia) * (total / 2.0)\n",
        "\n",
        "class_weights = {0: weight_0, 1: weight_1}\n",
        "\n",
        "print(\"Class Weights:\")\n",
        "print(f\"NORMAL (0): {weight_0:.4f}\")\n",
        "print(f\"PNEUMONIA (1): {weight_1:.4f}\")\n"
      ],
      "metadata": {
        "id": "lPerRLJDCyxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup callbacks (opsional tapi disarankan)\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=0.00001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Training\n",
        "print(\"Memulai training...\")\n",
        "print(\"Ini akan memakan waktu 10-15 menit tergantung GPU\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=25,  # Sesuaikan dengan waktu yang tersisa\n",
        "    validation_data=validation_generator,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"âœ“ Training selesai!\")\n"
      ],
      "metadata": {
        "id": "MmVdv5nhC2qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 9: EVALUATION\n",
        "# ==========================================\n",
        "\n",
        "# Extract history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "# Create plots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Accuracy plot\n",
        "ax1.plot(epochs_range, acc, 'r', label='Training Accuracy', linewidth=2)\n",
        "ax1.plot(epochs_range, val_acc, 'b', label='Validation Accuracy', linewidth=2)\n",
        "ax1.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Loss plot\n",
        "ax2.plot(epochs_range, loss, 'r', label='Training Loss', linewidth=2)\n",
        "ax2.plot(epochs_range, val_loss, 'b', label='Validation Loss', linewidth=2)\n",
        "ax2.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final metrics\n",
        "print(\"\\nFinal Training Metrics:\")\n",
        "print(f\"Training Accuracy: {acc[-1]:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_acc[-1]:.4f}\")\n",
        "print(f\"Training Loss: {loss[-1]:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss[-1]:.4f}\")\n"
      ],
      "metadata": {
        "id": "n2IORS_yErom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset test generator\n",
        "test_generator.reset()\n",
        "\n",
        "# Predict\n",
        "print(\"Melakukan prediksi pada test set...\")\n",
        "predictions = model.predict(test_generator, verbose=1)\n",
        "\n",
        "# Convert to binary\n",
        "y_pred = (predictions > 0.5).astype(int).flatten()\n",
        "y_true = test_generator.classes\n",
        "\n",
        "print(f\"\\nâœ“ Prediksi selesai!\")\n",
        "print(f\"Total prediksi: {len(y_pred)}\")\n"
      ],
      "metadata": {
        "id": "wNP2ckFrEwz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Normal', 'Pneumonia'],\n",
        "            yticklabels=['Normal', 'Pneumonia'],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.ylabel('Actual Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print CM values\n",
        "print(\"\\nConfusion Matrix Values:\")\n",
        "print(f\"True Negative (TN): {cm[0,0]}\")\n",
        "print(f\"False Positive (FP): {cm[0,1]}\")\n",
        "print(f\"False Negative (FN): {cm[1,0]}\")\n",
        "print(f\"True Positive (TP): {cm[1,1]}\")\n"
      ],
      "metadata": {
        "id": "ydFkJibVE3b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "report = classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    target_names=['Normal', 'Pneumonia'],\n",
        "    digits=4\n",
        ")\n",
        "\n",
        "print(\"\\nCLASSIFICATION REPORT\")\n",
        "print(\"=\" * 60)\n",
        "print(report)\n",
        "\n",
        "# Calculate additional metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(\"\\nOVERALL METRICS:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Evaluasi\n",
        "if accuracy >= 0.85:\n",
        "    print(\"\\nâœ“ EXCELLENT! Model mencapai target minimum (â‰¥85%)\")\n",
        "elif accuracy >= 0.80:\n",
        "    print(\"\\nâœ“ GOOD! Model cukup baik (â‰¥80%)\")\n",
        "else:\n",
        "    print(\"\\nâš  Model perlu improvement (<80%)\")\n"
      ],
      "metadata": {
        "id": "OigFJMaOFIqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“‹ ANALISIS HASIL MODEL\n",
        "\n",
        "### 1. Performance Summary\n",
        "- **Accuracy**: [0.9733]%\n",
        "- **Precision**: [0.9721]%\n",
        "- **Recall**: [0.9789]%\n",
        "- **F1-Score**: [0.9755]%\n",
        "\n",
        "### 2. Interpretasi Confusion Matrix\n",
        "- True Positive (TP): [837]\n",
        "- True Negative (TN): [693]\n",
        "- False Positive (FP): [24]\n",
        "- False Negative (FN): [18]\n",
        "\n",
        "**Analisis:**\n",
        "[Tulis analisis Anda di sini. Contoh:]\n",
        "- Model berhasil mengidentifikasi X dari Y kasus pneumonia\n",
        "- Terjadi Z false negative yang perlu diperhatikan\n",
        "- Model berhasil mengidentifikasi 837 kasus positif secara benar, menunjukkan kemampuan deteksi yang sangat baik.\n",
        "- Terdapat 693 data negatif yang berhasil diklasifikasikan dengan benar, menandakan model tidak bias terhadap kelas positif.\n",
        "- False Positive sebanyak 24 menunjukkan masih ada sedikit data negatif yang salah diprediksi sebagai positif.\n",
        "- False Negative sebanyak 18 perlu diperhatikan karena kasus ini berpotensi lebih kritis (misalnya pada diagnosis penyakit), namun jumlahnya relatif kecil.\n",
        "- Secara keseluruhan, tingkat kesalahan model sangat rendah, sehingga model dapat dikategorikan andal.\n",
        "\n",
        "### 3. Overfitting/Underfitting Assessment\n",
        "**Berdasarkan grafik accuracy dan loss:**\n",
        "[Tulis analisis Anda. Contoh:]\n",
        "- Kurva training dan validation accuracy saling mendekati dan konvergen\n",
        "- Nilai training loss dan validation loss menurun secara stabil tanpa gap signifikan\n",
        "\n",
        "### 4. Challenges yang Dihadapi\n",
        "[Tuliskan kendala yang Anda hadapi:]\n",
        "1.Proses tuning hyperparameter membutuhkan waktu dan eksperimen yang cukup panjang.\n",
        "2.Keterbatasan jumlah data pada beberapa kelas yang berpotensi menyebabkan ketidakseimbangan data.\n",
        "3.Risiko kesalahan pada kasus false negative yang perlu diminimalkan, terutama jika model digunakan pada sistem kritis.\n",
        "\n",
        "### 5. Improvement Suggestions\n",
        "[Tuliskan ide improvement:]\n",
        "1. Menambahkan jumlah data latih, khususnya pada kelas minoritas.\n",
        "2. Melakukan hyperparameter tuning lebih lanjut (learning rate, batch size, optimizer).\n",
        "3. Mencoba arsitektur model lain yang lebih kompleks.\n",
        "4. Mengimplementasikan transfer learning untuk meningkatkan performa dan efisiensi training.\n",
        "5. Menggunakan teknik data augmentation untuk meningkatkan variasi data.\n",
        "6. Menerapkan regularisasi tambahan (Dropout atau L2 Regularization) untuk menjaga stabilitas model.\n"
      ],
      "metadata": {
        "id": "EHhcQWhdFWaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BAGIAN 10: SAVE MODEL\n",
        "# ==========================================\n",
        "\n",
        "# Save model\n",
        "model_name = \"pneumonia_detection_model.h5\"\n",
        "model.save(model_name)\n",
        "\n",
        "print(f\"âœ“ Model berhasil disimpan: {model_name}\")\n",
        "\n",
        "# Download model (opsional)\n",
        "from google.colab import files\n",
        "# files.download(model_name)  # Uncomment untuk download\n"
      ],
      "metadata": {
        "id": "h9SHWGHXJes3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Summary Report\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"RINGKASAN UJIAN AKHIR PRAKTIKUM AI\".center(60))\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nNama: [NENI Uci Naibaho]\")\n",
        "print(f\"NPM: [2302050119]\")\n",
        "print(f\"Tanggal: [12 Jan 2026]\")\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"HASIL MODEL\".center(60))\n",
        "print(\"-\" * 60)\n",
        "print(f\"\\nArsitektur: CNN dengan 3 Convolutional Blocks\")\n",
        "print(f\"Total Parameters: {model.count_params():,}\")\n",
        "print(f\"Training Epochs: {len(history.history['accuracy'])}\")\n",
        "print(f\"\\nFinal Metrics:\")\n",
        "print(f\"  - Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"  - Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "print(f\"  - Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"  - Precision: {precision:.4f}\")\n",
        "print(f\"  - Recall: {recall:.4f}\")\n",
        "print(f\"  - F1-Score: {f1:.4f}\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SELESAI - Silakan screenshot untuk dokumentasi\".center(60))\n",
        "print(\"=\" * 60)\n"
      ],
      "metadata": {
        "id": "C8lwFDRLJg2x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}